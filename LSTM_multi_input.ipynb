{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv').iloc[:, :]\n",
    "vocab = ['C_E_F_T',\n",
    "         'C_E_F_C',\n",
    "         'C_E_F_O',\n",
    "         'A_E_F_T',\n",
    "         'A_E_F_O',\n",
    "         'A_E_F_C',\n",
    "         'G_E_F_C',\n",
    "         'G_E_F_T',\n",
    "         'G_E_F_O',\n",
    "         'A_E_M_T',\n",
    "         'A_E_M_O',\n",
    "         'A_E_M_C',\n",
    "         'G_E_M_O',\n",
    "         'G_E_M_C',\n",
    "         'G_E_M_T',\n",
    "         'C_E_M_O',\n",
    "         'C_E_M_C',\n",
    "         'C_E_M_T',\n",
    "         'C_H_F_CO',\n",
    "         'C_H_F_CT',\n",
    "         'C_H_F_OT',\n",
    "         'G_H_F_OT',\n",
    "         'G_H_F_CO',\n",
    "         'G_H_F_CT',\n",
    "         'A_H_F_CT',\n",
    "         'A_H_F_OT',\n",
    "         'A_H_F_CO',\n",
    "         'C_H_M_CO',\n",
    "         'C_H_M_CT',\n",
    "         'C_H_M_OT',\n",
    "         'A_H_M_CT',\n",
    "         'A_H_M_OT',\n",
    "         'A_H_M_CO',\n",
    "         'G_H_M_OT',\n",
    "         'G_H_M_CO',\n",
    "         'G_H_M_CT', ]\n",
    "\n",
    "labels = ['correct',\n",
    "          'wrong',\n",
    "          'type',\n",
    "          'orientation',\n",
    "          'color']\n",
    "\n",
    "types = ['INTRO',\n",
    "         'CORE',\n",
    "         'FLEX',\n",
    "         'TRIK',\n",
    "         'DELY'\n",
    "]\n",
    "\n",
    "topics = ['cards',\n",
    "          'animals',\n",
    "          'geometry'\n",
    "    \n",
    "]\n",
    "\n",
    "feat = ['type',\n",
    "        'color',\n",
    "        'orientation',\n",
    "        'dual'\n",
    "]\n",
    "\n",
    "age = ['8-10','11-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_int(qts,vocab, labels, types, feat, topics, n_steps, age):\n",
    "    integ = list()\n",
    "    for i,x in enumerate(qts):\n",
    "        if i != n_steps:\n",
    "            features = list()\n",
    "            #features.append(vocab.index(qts[i, 4]))\n",
    "            #features.append(qts[i, 2])\n",
    "            features.append(types.index(qts[i, 9]))\n",
    "            features.append(feat.index(qts[i, 10]))\n",
    "            features.append(topics.index(qts[i, 6]))\n",
    "            features.append(age.index(qts[i, 7]))\n",
    "            features.append(labels.index(qts[i, 5]))\n",
    "        else:\n",
    "            features = list()\n",
    "            #features.append(vocab.index(qts[i, 4]))\n",
    "            #features.append(qts[i, 2])\n",
    "            features.append(types.index(qts[i, 9]))\n",
    "            features.append(feat.index(qts[i, 10]))\n",
    "            features.append(topics.index(qts[i, 6]))\n",
    "            features.append(age.index(qts[i, 7]))\n",
    "            features.append(-1)\n",
    "        integ.append(features)\n",
    "    return integ\n",
    "\n",
    "def split_sequence(data, n_steps, vocab, labels, types, feat, topics, age):\n",
    "    X, Y = list(), list()\n",
    "    users = list(dict.fromkeys(data.loc[:, \"user\"]))\n",
    "    for u in users:\n",
    "        sequence = data[data.user == u]\n",
    "        for i in range(len(sequence)):\n",
    "            end_idx = i + n_steps\n",
    "            if end_idx > len(sequence)-1:\n",
    "                break\n",
    "            x = seq_to_int(sequence.iloc[i:end_idx+1, :].values, vocab, labels, types, feat, topics, n_steps, age)\n",
    "            y = labels.index(str(sequence.iloc[end_idx, 5]))\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:29<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "data_train = data.iloc[:]\n",
    "y_train = list()\n",
    "X_train = list()\n",
    "\n",
    "\n",
    "for i in tqdm(range(10,18)):\n",
    "    X_seq, y_seq = split_sequence(data_train, i, vocab, labels, types, feat, topics, age)\n",
    "    for x in X_seq:\n",
    "        X_train.append(x)\n",
    "    for _y in y_seq:\n",
    "        y_train.append(_y)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_train = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data_val = pd.read_csv('validation.csv')\n",
    "y_val = list()\n",
    "X_val = list()\n",
    "\n",
    "\n",
    "for i in tqdm(range(10,18)):\n",
    "    X_seq, y_seq = split_sequence(data_val, i, vocab, labels, types, feat, topics, age)\n",
    "    for x in X_seq:\n",
    "        X_val.append(x)\n",
    "    for _y in y_seq:\n",
    "        y_val.append(_y)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "X_val = np.asarray(X_val)\n",
    "X_val = pad_sequences(X_val, value=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, value=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = int(2/3 * (X_train.shape[1]+X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 18, 50)            11200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 18, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 255       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 31,655\n",
      "Trainable params: 31,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=5))\n",
    "amsgrad = Adam(amsgrad=False)\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer=amsgrad, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59764 samples, validate on 5940 samples\n",
      "Epoch 1/500\n",
      "59764/59764 [==============================] - 48s 810us/step - loss: 5.2251 - sparse_categorical_accuracy: 0.3754 - val_loss: 1.0871 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 2/500\n",
      "59764/59764 [==============================] - 50s 832us/step - loss: 4.9360 - sparse_categorical_accuracy: 0.4648 - val_loss: 0.9901 - val_sparse_categorical_accuracy: 0.5022\n",
      "Epoch 3/500\n",
      "59764/59764 [==============================] - 52s 862us/step - loss: 4.6284 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.9131 - val_sparse_categorical_accuracy: 0.5503\n",
      "Epoch 4/500\n",
      "59764/59764 [==============================] - 46s 767us/step - loss: 4.2675 - sparse_categorical_accuracy: 0.5609 - val_loss: 0.8385 - val_sparse_categorical_accuracy: 0.5774\n",
      "Epoch 5/500\n",
      "59764/59764 [==============================] - 46s 769us/step - loss: 3.9406 - sparse_categorical_accuracy: 0.5865 - val_loss: 0.7849 - val_sparse_categorical_accuracy: 0.5998\n",
      "Epoch 6/500\n",
      "59764/59764 [==============================] - 50s 834us/step - loss: 3.7376 - sparse_categorical_accuracy: 0.6025 - val_loss: 0.7392 - val_sparse_categorical_accuracy: 0.6332\n",
      "Epoch 7/500\n",
      "59764/59764 [==============================] - 64s 1ms/step - loss: 3.5757 - sparse_categorical_accuracy: 0.6165 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.6342\n",
      "Epoch 8/500\n",
      "59764/59764 [==============================] - 52s 873us/step - loss: 3.4259 - sparse_categorical_accuracy: 0.6304 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.6495\n",
      "Epoch 9/500\n",
      "59764/59764 [==============================] - 52s 868us/step - loss: 3.3205 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.6554 - val_sparse_categorical_accuracy: 0.6729\n",
      "Epoch 10/500\n",
      "59764/59764 [==============================] - 48s 808us/step - loss: 3.2331 - sparse_categorical_accuracy: 0.6426 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.6704\n",
      "Epoch 11/500\n",
      "23400/59764 [==========>...................] - ETA: 32s - loss: 3.1961 - sparse_categorical_accuracy: 0.6418"
     ]
    }
   ],
   "source": [
    "class_weight = {\n",
    "    0: 1.,\n",
    "    1: 1.,\n",
    "    2: 5.,\n",
    "    3: 5.,\n",
    "    4: 5.\n",
    "}\n",
    "history = model.fit(X_train, np.asarray(y_train), epochs=500, batch_size=300, shuffle=True, verbose=1, validation_data=(X_val, y_val), class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model2.h5\")\n",
    "#from keras.models import load_model\n",
    "#model = load_model(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list()\n",
    "X_test = list()\n",
    "\n",
    "\n",
    "for i in tqdm(range(10, 18)):\n",
    "    X_seq, y_seq = split_sequence(data_test, i, vocab, labels, types, feat, topics, age)\n",
    "    for x in X_seq:\n",
    "        X_test.append(x)\n",
    "    for _y in y_seq:\n",
    "        y_test.append(_y)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "y_test = np.asarray(y_test)\n",
    "X_test = np.asarray(X_test)\n",
    "X_test = pad_sequences(X_test, value=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred.argmax(axis=1)))\n",
    "matrix = confusion_matrix(y_test, y_pred.argmax(axis=1))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
