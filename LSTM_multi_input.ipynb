{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('induce-data-2019-08-08.csv').iloc[:, :]\n",
    "vocab = ['C_E_F_T',\n",
    "         'C_E_F_C',\n",
    "         'C_E_F_O',\n",
    "         'A_E_F_T',\n",
    "         'A_E_F_O',\n",
    "         'A_E_F_C',\n",
    "         'G_E_F_C',\n",
    "         'G_E_F_T',\n",
    "         'G_E_F_O',\n",
    "         'A_E_M_T',\n",
    "         'A_E_M_O',\n",
    "         'A_E_M_C',\n",
    "         'G_E_M_O',\n",
    "         'G_E_M_C',\n",
    "         'G_E_M_T',\n",
    "         'C_E_M_O',\n",
    "         'C_E_M_C',\n",
    "         'C_E_M_T',\n",
    "         'C_H_F_CO',\n",
    "         'C_H_F_CT',\n",
    "         'C_H_F_OT',\n",
    "         'G_H_F_OT',\n",
    "         'G_H_F_CO',\n",
    "         'G_H_F_CT',\n",
    "         'A_H_F_CT',\n",
    "         'A_H_F_OT',\n",
    "         'A_H_F_CO',\n",
    "         'C_H_M_CO',\n",
    "         'C_H_M_CT',\n",
    "         'C_H_M_OT',\n",
    "         'A_H_M_CT',\n",
    "         'A_H_M_OT',\n",
    "         'A_H_M_CO',\n",
    "         'G_H_M_OT',\n",
    "         'G_H_M_CO',\n",
    "         'G_H_M_CT', ]\n",
    "\n",
    "labels = ['correct',\n",
    "          'wrong',\n",
    "          'type',\n",
    "          'orientation',\n",
    "          'color']\n",
    "\n",
    "types = ['INTRO',\n",
    "         'CORE',\n",
    "         'FLEX',\n",
    "         'TRIK',\n",
    "         'DELY'\n",
    "]\n",
    "\n",
    "topics = ['cards',\n",
    "          'animals',\n",
    "          'geometry'\n",
    "    \n",
    "]\n",
    "\n",
    "feat = ['type',\n",
    "        'color',\n",
    "        'orientation',\n",
    "        'dual'\n",
    "]\n",
    "\n",
    "age = ['8-10','11-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_int(qts,vocab, labels, types, feat, topics, n_steps, age):\n",
    "    integ = list()\n",
    "    for i,x in enumerate(qts):\n",
    "        if i != n_steps:\n",
    "            features = list()\n",
    "            features.append(vocab.index(qts[i, 4]))\n",
    "            features.append(labels.index(qts[i, 5]))\n",
    "            features.append(qts[i, 2])\n",
    "            features.append(types.index(qts[i, 9]))\n",
    "            features.append(feat.index(qts[i, 10]))\n",
    "            features.append(topics.index(qts[i, 6]))\n",
    "            features.append(age.index(qts[i, 7]))\n",
    "        else:\n",
    "            features = list()\n",
    "            features.append(vocab.index(qts[i, 4]))\n",
    "            features.append(-1)\n",
    "            features.append(qts[i, 2])\n",
    "            features.append(types.index(qts[i, 9]))\n",
    "            features.append(feat.index(qts[i, 10]))\n",
    "            features.append(topics.index(qts[i, 6]))\n",
    "            features.append(age.index(qts[i, 7]))\n",
    "        integ.append(features)\n",
    "    return integ\n",
    "\n",
    "def split_sequence(data, n_steps, vocab, labels, types, feat, topics, age):\n",
    "    X, Y = list(), list()\n",
    "    users = list(dict.fromkeys(data.loc[:, \"user\"]))\n",
    "    for u in users:\n",
    "        sequence = data[data.user == u]\n",
    "        for i in range(len(sequence)):\n",
    "            end_idx = i + n_steps\n",
    "            if end_idx > len(sequence)-1:\n",
    "                break\n",
    "            x = seq_to_int(sequence.iloc[i:end_idx+1, :].values, vocab, labels, types, feat, topics, n_steps, age)\n",
    "            y = labels.index(str(sequence.iloc[end_idx, 5]))\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11173 2794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train, data_test = np.split(data.sample(frac=1, random_state=42), \n",
    "                                   [int(0.8 * len(data))])\n",
    "print(len(data_train),len(data_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:04<00:18,  4.55s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:08<00:13,  4.48s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:13<00:09,  4.58s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:18<00:04,  4.53s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:25<00:00,  5.07s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:07,  1.82s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:04,  1.59s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.39s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# n_steps = 10\n",
    "\n",
    "X_train_split = list()\n",
    "y_train_split = list()\n",
    "\n",
    "\n",
    "for i in tqdm(range(5, 10)):\n",
    "    X_seq, y_seq = split_sequence(data_train, i, vocab, labels, types, feat, topics, age)\n",
    "    for x in X_seq:\n",
    "        X_train_split.append(x)\n",
    "    for _y in y_seq:\n",
    "        y_train_split.append(_y)\n",
    "y_train = np_utils.to_categorical(y_train_split)\n",
    "X_train = np.array(X_train_split)\n",
    "\n",
    "\n",
    "\n",
    "X_test_split = list()\n",
    "y_test_split = list()\n",
    "\n",
    "\n",
    "for i in tqdm(range(5, 10)):\n",
    "    X_seq, y_seq = split_sequence(data_test, i, vocab, labels, types, feat, topics, age)\n",
    "    for x in X_seq:\n",
    "        X_test_split.append(x)\n",
    "    for _y in y_seq:\n",
    "        y_test_split.append(_y)\n",
    "y_test = np_utils.to_categorical(y_test_split)\n",
    "X_test = np.array(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(row):\n",
    "    encoded = []\n",
    "    for i in range(len(row)):\n",
    "        encoded.append([1 if row[i] == j else 0 for j in range(99)])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  ...\n",
      "  [24  2 44 ...  3  1  1]\n",
      "  [22  4 25 ...  3  2  1]\n",
      "  [23 -1 56 ...  3  2  1]]\n",
      "\n",
      " [[99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  ...\n",
      "  [22  4 25 ...  3  2  1]\n",
      "  [23  2 56 ...  3  2  1]\n",
      "  [21 -1 42 ...  3  2  1]]\n",
      "\n",
      " [[99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  [99 99 99 ... 99 99 99]\n",
      "  ...\n",
      "  [23  2 56 ...  3  2  1]\n",
      "  [21  3 42 ...  3  2  1]\n",
      "  [32 -1 35 ...  3  1  1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[17  0 14 ...  0  0  0]\n",
      "  [22  4 49 ...  3  2  0]\n",
      "  [20  3 60 ...  3  0  0]\n",
      "  ...\n",
      "  [27  4 39 ...  3  0  0]\n",
      "  [35  4 57 ...  3  2  0]\n",
      "  [ 4 -1  1 ...  2  1  0]]\n",
      "\n",
      " [[22  4 49 ...  3  2  0]\n",
      "  [20  3 60 ...  3  0  0]\n",
      "  [34  4 50 ...  3  2  0]\n",
      "  ...\n",
      "  [35  4 57 ...  3  2  0]\n",
      "  [ 4  1  1 ...  2  1  0]\n",
      "  [13 -1 16 ...  1  2  0]]\n",
      "\n",
      " [[20  3 60 ...  3  0  0]\n",
      "  [34  4 50 ...  3  2  0]\n",
      "  [26  3 62 ...  3  1  0]\n",
      "  ...\n",
      "  [ 4  1  1 ...  2  1  0]\n",
      "  [13  0 16 ...  1  2  0]\n",
      "  [29 -1 55 ...  3  0  0]]]\n",
      "(48095, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, value=99)\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "n_hidden = int(2/3 * (X_train.shape[1]+X_train.shape[2]))\n",
    "print(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ambroiserenaud/anaconda3/envs/chili/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 10, 11)            836       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 11)            0         \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 11)                1012      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,908\n",
      "Trainable params: 1,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=n_hidden, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=n_hidden, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=5))\n",
    "amsgrad = Adam(amsgrad=False)\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer=amsgrad, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48095/48095 [==============================] - 23s 475us/step - loss: 1.4722 - categorical_accuracy: 0.3230\n",
      "Epoch 2/20\n",
      "48095/48095 [==============================] - 11s 228us/step - loss: 1.1048 - categorical_accuracy: 0.4718\n",
      "Epoch 3/20\n",
      "48095/48095 [==============================] - 11s 228us/step - loss: 0.9710 - categorical_accuracy: 0.4852\n",
      "Epoch 4/20\n",
      "48095/48095 [==============================] - 11s 219us/step - loss: 0.9420 - categorical_accuracy: 0.4909\n",
      "Epoch 5/20\n",
      "48095/48095 [==============================] - 11s 219us/step - loss: 0.9290 - categorical_accuracy: 0.4891\n",
      "Epoch 6/20\n",
      "48095/48095 [==============================] - 11s 224us/step - loss: 0.9230 - categorical_accuracy: 0.4892\n",
      "Epoch 7/20\n",
      "48095/48095 [==============================] - 11s 234us/step - loss: 0.9173 - categorical_accuracy: 0.4912\n",
      "Epoch 8/20\n",
      "48095/48095 [==============================] - 11s 226us/step - loss: 0.9145 - categorical_accuracy: 0.4919\n",
      "Epoch 9/20\n",
      "48095/48095 [==============================] - 12s 252us/step - loss: 0.9111 - categorical_accuracy: 0.4938\n",
      "Epoch 10/20\n",
      "48095/48095 [==============================] - 12s 252us/step - loss: 0.9089 - categorical_accuracy: 0.4966\n",
      "Epoch 11/20\n",
      "48095/48095 [==============================] - 12s 242us/step - loss: 0.9083 - categorical_accuracy: 0.4960\n",
      "Epoch 12/20\n",
      "48095/48095 [==============================] - 11s 237us/step - loss: 0.9059 - categorical_accuracy: 0.4990\n",
      "Epoch 13/20\n",
      "48095/48095 [==============================] - 11s 237us/step - loss: 0.9061 - categorical_accuracy: 0.4971\n",
      "Epoch 14/20\n",
      "48095/48095 [==============================] - 11s 236us/step - loss: 0.9048 - categorical_accuracy: 0.5011\n",
      "Epoch 15/20\n",
      "48095/48095 [==============================] - 11s 238us/step - loss: 0.9042 - categorical_accuracy: 0.5021\n",
      "Epoch 16/20\n",
      "48095/48095 [==============================] - 11s 231us/step - loss: 0.9037 - categorical_accuracy: 0.5036\n",
      "Epoch 17/20\n",
      "48095/48095 [==============================] - 11s 232us/step - loss: 0.9017 - categorical_accuracy: 0.5096\n",
      "Epoch 18/20\n",
      "48095/48095 [==============================] - 11s 228us/step - loss: 0.8997 - categorical_accuracy: 0.5127\n",
      "Epoch 19/20\n",
      "48095/48095 [==============================] - 11s 229us/step - loss: 0.8977 - categorical_accuracy: 0.5157\n",
      "Epoch 20/20\n",
      "48095/48095 [==============================] - 11s 225us/step - loss: 0.8950 - categorical_accuracy: 0.5217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5cf05490>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
