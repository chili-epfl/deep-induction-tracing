{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\nfrom keras import Sequential\nfrom keras.layers import LSTM, Dense\nfrom keras.utils import np_utils",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Data preparation",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "\ndata \u003d pd.read_csv(\u0027induce-data-2019-08-08.csv\u0027).iloc[:200, :]\nvocab \u003d [\u0027C_E_F_T\u0027,\n         \u0027C_E_F_C\u0027,\n         \u0027C_E_F_O\u0027,\n         \u0027A_E_F_T\u0027,\n         \u0027A_E_F_O\u0027,\n         \u0027A_E_F_C\u0027,\n         \u0027G_E_F_C\u0027,\n         \u0027G_E_F_T\u0027,\n         \u0027G_E_F_O\u0027,\n         \u0027A_E_M_T\u0027,\n         \u0027A_E_M_O\u0027,\n         \u0027A_E_M_C\u0027,\n         \u0027G_E_M_O\u0027,\n         \u0027G_E_M_C\u0027,\n         \u0027G_E_M_T\u0027,\n         \u0027C_E_M_O\u0027,\n         \u0027C_E_M_C\u0027,\n         \u0027C_E_M_T\u0027,\n         \u0027C_H_F_CO\u0027,\n         \u0027C_H_F_CT\u0027,\n         \u0027C_H_F_OT\u0027,\n         \u0027G_H_F_OT\u0027,\n         \u0027G_H_F_CO\u0027,\n         \u0027G_H_F_CT\u0027,\n         \u0027A_H_F_CT\u0027,\n         \u0027A_H_F_OT\u0027,\n         \u0027A_H_F_CO\u0027,\n         \u0027C_H_M_CO\u0027,\n         \u0027C_H_M_CT\u0027,\n         \u0027C_H_M_OT\u0027,\n         \u0027A_H_M_CT\u0027,\n         \u0027A_H_M_OT\u0027,\n         \u0027A_H_M_CO\u0027,\n         \u0027G_H_M_OT\u0027,\n         \u0027G_H_M_CO\u0027,\n         \u0027G_H_M_CT\u0027, ]\nlabels \u003d [\u0027correct\u0027,\n          \u0027wrong\u0027,\n          \u0027type\u0027,\n          \u0027orientation\u0027,\n          \u0027color\u0027]\ndef seq_to_int(qts, asw, vocab, labels):\n    integ \u003d list()\n    for i,x in enumerate(qts):\n        features \u003d list()\n        features.append(vocab.index(x))\n        features.append(labels.index(asw.iloc[i]))\n        integ.append(features)\n    return integ\ndef split_sequence(sequence, n_steps, vocab, labels):\n    X, Y \u003d list(), list()\n    for i in range(len(sequence)):\n        end_idx \u003d i + n_steps\n        if end_idx \u003e len(sequence)-1:\n            break\n        x \u003d seq_to_int(sequence.iloc[i:end_idx, 4], sequence.iloc[i:end_idx, 5], vocab, labels)\n        y \u003d labels.index(str(sequence.iloc[end_idx, 5]))\n        X.append(x)\n        Y.append(y)\n    return np.array(X), np.array(Y)\n\n"
    },
    {
      "cell_type": "markdown",
      "source": "### Test split_sequence\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(array([[[0, 0],\n        [1, 0],\n        [2, 0],\n        [3, 0],\n        [4, 0]],\n\n       [[1, 0],\n        [2, 0],\n        [3, 0],\n        [4, 0],\n        [5, 1]],\n\n       [[2, 0],\n        [3, 0],\n        [4, 0],\n        [5, 1],\n        [6, 0]],\n\n       [[3, 0],\n        [4, 0],\n        [5, 1],\n        [6, 0],\n        [7, 0]],\n\n       [[4, 0],\n        [5, 1],\n        [6, 0],\n        [7, 0],\n        [8, 0]]]), array([1, 0, 0, 0, 0]))\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(split_sequence(data.iloc[:10, :], 5, vocab, labels))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## The model\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": "n_features \u003d 2\nn_steps \u003d 5\nX, Y \u003d split_sequence(data.iloc[:100, :], n_steps, vocab, labels)\nY \u003d np_utils.to_categorical(Y)\nX \u003d X.reshape((X.shape[0], X.shape[1], n_features))\n\nmodel \u003d Sequential()\nmodel.add(LSTM(50, activation\u003d\u0027relu\u0027, input_shape\u003d(n_steps, n_features)))\nmodel.add(Dense(5))\nmodel.compile(optimizer\u003d\u0027adam\u0027, loss\u003d\u0027mse\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            " - 0s - loss: 5.6416\n",
            "Epoch 2/200\n - 0s - loss: 4.0741\n",
            "Epoch 3/200\n - 0s - loss: 2.6709\n",
            "Epoch 4/200\n - 0s - loss: 1.6104\n",
            "Epoch 5/200\n - 0s - loss: 0.7804\n",
            "Epoch 6/200\n - 0s - loss: 0.3139\n",
            "Epoch 7/200\n - 0s - loss: 0.3063\n",
            "Epoch 8/200\n - 0s - loss: 0.4528\n",
            "Epoch 9/200\n",
            " - 0s - loss: 0.4342\n",
            "Epoch 10/200\n - 0s - loss: 0.3171\n",
            "Epoch 11/200\n",
            " - 0s - loss: 0.2352\n",
            "Epoch 12/200\n",
            " - 0s - loss: 0.2135\n",
            "Epoch 13/200\n",
            " - 0s - loss: 0.2197\n",
            "Epoch 14/200\n",
            " - 0s - loss: 0.2229\n",
            "Epoch 15/200\n",
            " - 0s - loss: 0.2163\n",
            "Epoch 16/200\n",
            " - 0s - loss: 0.2014\n",
            "Epoch 17/200\n",
            " - 0s - loss: 0.1866\n",
            "Epoch 18/200\n",
            " - 0s - loss: 0.1755\n",
            "Epoch 19/200\n",
            " - 0s - loss: 0.1672\n",
            "Epoch 20/200\n",
            " - 0s - loss: 0.1606\n",
            "Epoch 21/200\n",
            " - 0s - loss: 0.1533\n",
            "Epoch 22/200\n",
            " - 0s - loss: 0.1477\n",
            "Epoch 23/200\n",
            " - 0s - loss: 0.1409\n",
            "Epoch 24/200\n",
            " - 0s - loss: 0.1357\n",
            "Epoch 25/200\n",
            " - 0s - loss: 0.1312\n",
            "Epoch 26/200\n",
            " - 0s - loss: 0.1275\n",
            "Epoch 27/200\n",
            " - 0s - loss: 0.1240\n",
            "Epoch 28/200\n",
            " - 0s - loss: 0.1216\n",
            "Epoch 29/200\n",
            " - 0s - loss: 0.1202\n",
            "Epoch 30/200\n",
            " - 0s - loss: 0.1185\n",
            "Epoch 31/200\n",
            " - 0s - loss: 0.1169\n",
            "Epoch 32/200\n",
            " - 0s - loss: 0.1156\n",
            "Epoch 33/200\n",
            " - 0s - loss: 0.1144\n",
            "Epoch 34/200\n",
            " - 0s - loss: 0.1138\n",
            "Epoch 35/200\n",
            " - 0s - loss: 0.1122\n",
            "Epoch 36/200\n",
            " - 0s - loss: 0.1118\n",
            "Epoch 37/200\n",
            " - 0s - loss: 0.1107\n",
            "Epoch 38/200\n",
            " - 0s - loss: 0.1092\n",
            "Epoch 39/200\n",
            " - 0s - loss: 0.1086\n",
            "Epoch 40/200\n",
            " - 0s - loss: 0.1079\n",
            "Epoch 41/200\n",
            " - 0s - loss: 0.1079\n",
            "Epoch 42/200\n",
            " - 0s - loss: 0.1062\n",
            "Epoch 43/200\n",
            " - 0s - loss: 0.1055\n",
            "Epoch 44/200\n",
            " - 0s - loss: 0.1050\n",
            "Epoch 45/200\n",
            " - 0s - loss: 0.1047\n",
            "Epoch 46/200\n",
            " - 0s - loss: 0.1036\n",
            "Epoch 47/200\n",
            " - 0s - loss: 0.1033\n",
            "Epoch 48/200\n",
            " - 0s - loss: 0.1030\n",
            "Epoch 49/200\n",
            " - 0s - loss: 0.1024\n",
            "Epoch 50/200\n",
            " - 0s - loss: 0.1020\n",
            "Epoch 51/200\n - 0s - loss: 0.1025\n",
            "Epoch 52/200\n",
            " - 0s - loss: 0.1014\n",
            "Epoch 53/200\n",
            " - 0s - loss: 0.1011\n",
            "Epoch 54/200\n",
            " - 0s - loss: 0.1002\n",
            "Epoch 55/200\n",
            " - 0s - loss: 0.1007\n",
            "Epoch 56/200\n",
            " - 0s - loss: 0.0998\n",
            "Epoch 57/200\n",
            " - 0s - loss: 0.1003\n",
            "Epoch 58/200\n",
            " - 0s - loss: 0.0995\n",
            "Epoch 59/200\n",
            " - 0s - loss: 0.0993\n",
            "Epoch 60/200\n",
            " - 0s - loss: 0.0990\n",
            "Epoch 61/200\n - 0s - loss: 0.0994\n",
            "Epoch 62/200\n",
            " - 0s - loss: 0.0986\n",
            "Epoch 63/200\n",
            " - 0s - loss: 0.0984\n",
            "Epoch 64/200\n",
            " - 0s - loss: 0.0982\n",
            "Epoch 65/200\n",
            " - 0s - loss: 0.0990\n",
            "Epoch 66/200\n",
            " - 0s - loss: 0.0982\n",
            "Epoch 67/200\n",
            " - 0s - loss: 0.0980\n",
            "Epoch 68/200\n",
            " - 0s - loss: 0.0975\n",
            "Epoch 69/200\n",
            " - 0s - loss: 0.0975\n",
            "Epoch 70/200\n",
            " - 0s - loss: 0.0971\n",
            "Epoch 71/200\n",
            " - 0s - loss: 0.0966\n",
            "Epoch 72/200\n",
            " - 0s - loss: 0.0973\n",
            "Epoch 73/200\n",
            " - 0s - loss: 0.0970\n",
            "Epoch 74/200\n",
            " - 0s - loss: 0.0969\n",
            "Epoch 75/200\n",
            " - 0s - loss: 0.0964\n",
            "Epoch 76/200\n",
            " - 0s - loss: 0.0972\n",
            "Epoch 77/200\n",
            " - 0s - loss: 0.0962\n",
            "Epoch 78/200\n",
            " - 0s - loss: 0.0977\n",
            "Epoch 79/200\n",
            " - 0s - loss: 0.0961\n",
            "Epoch 80/200\n",
            " - 0s - loss: 0.0960\n",
            "Epoch 81/200\n",
            " - 0s - loss: 0.0957\n",
            "Epoch 82/200\n",
            " - 0s - loss: 0.0955\n",
            "Epoch 83/200\n",
            " - 0s - loss: 0.0956\n",
            "Epoch 84/200\n",
            " - 0s - loss: 0.0957\n",
            "Epoch 85/200\n",
            " - 0s - loss: 0.0955\n",
            "Epoch 86/200\n",
            " - 0s - loss: 0.0959\n",
            "Epoch 87/200\n",
            " - 0s - loss: 0.0957\n",
            "Epoch 88/200\n - 0s - loss: 0.0952\n",
            "Epoch 89/200\n",
            " - 0s - loss: 0.0947\n",
            "Epoch 90/200\n",
            " - 0s - loss: 0.0953\n",
            "Epoch 91/200\n - 0s - loss: 0.0947\n",
            "Epoch 92/200\n",
            " - 0s - loss: 0.0944\n",
            "Epoch 93/200\n",
            " - 0s - loss: 0.0943\n",
            "Epoch 94/200\n",
            " - 0s - loss: 0.0946\n",
            "Epoch 95/200\n",
            " - 0s - loss: 0.0946\n",
            "Epoch 96/200\n",
            " - 0s - loss: 0.0939\n",
            "Epoch 97/200\n",
            " - 0s - loss: 0.0942\n",
            "Epoch 98/200\n",
            " - 0s - loss: 0.0937\n",
            "Epoch 99/200\n",
            " - 0s - loss: 0.0935\n",
            "Epoch 100/200\n",
            " - 0s - loss: 0.0936\n",
            "Epoch 101/200\n - 0s - loss: 0.0940\n",
            "Epoch 102/200\n",
            " - 0s - loss: 0.0938\n",
            "Epoch 103/200\n",
            " - 0s - loss: 0.0942\n",
            "Epoch 104/200\n",
            " - 0s - loss: 0.0939\n",
            "Epoch 105/200\n",
            " - 0s - loss: 0.0931\n",
            "Epoch 106/200\n",
            " - 0s - loss: 0.0941\n",
            "Epoch 107/200\n",
            " - 0s - loss: 0.0930\n",
            "Epoch 108/200\n",
            " - 0s - loss: 0.0934\n",
            "Epoch 109/200\n",
            " - 0s - loss: 0.0927\n",
            "Epoch 110/200\n",
            " - 0s - loss: 0.0925\n",
            "Epoch 111/200\n",
            " - 0s - loss: 0.0926\n",
            "Epoch 112/200\n",
            " - 0s - loss: 0.0926\n",
            "Epoch 113/200\n",
            " - 0s - loss: 0.0923\n",
            "Epoch 114/200\n",
            " - 0s - loss: 0.0919\n",
            "Epoch 115/200\n",
            " - 0s - loss: 0.0919\n",
            "Epoch 116/200\n",
            " - 0s - loss: 0.0924\n",
            "Epoch 117/200\n",
            " - 0s - loss: 0.0920\n",
            "Epoch 118/200\n",
            " - 0s - loss: 0.0916\n",
            "Epoch 119/200\n - 0s - loss: 0.0916\n",
            "Epoch 120/200\n",
            " - 0s - loss: 0.0915\n",
            "Epoch 121/200\n",
            " - 0s - loss: 0.0911\n",
            "Epoch 122/200\n",
            " - 0s - loss: 0.0915\n",
            "Epoch 123/200\n",
            " - 0s - loss: 0.0908\n",
            "Epoch 124/200\n",
            " - 0s - loss: 0.0913\n",
            "Epoch 125/200\n",
            " - 0s - loss: 0.0908\n",
            "Epoch 126/200\n",
            " - 0s - loss: 0.0911\n",
            "Epoch 127/200\n",
            " - 0s - loss: 0.0909\n",
            "Epoch 128/200\n",
            " - 0s - loss: 0.0906\n",
            "Epoch 129/200\n",
            " - 0s - loss: 0.0902\n",
            "Epoch 130/200\n",
            " - 0s - loss: 0.0905\n",
            "Epoch 131/200\n",
            " - 0s - loss: 0.0908\n",
            "Epoch 132/200\n",
            " - 0s - loss: 0.0907\n",
            "Epoch 133/200\n",
            " - 0s - loss: 0.0902\n",
            "Epoch 134/200\n",
            " - 0s - loss: 0.0900\n",
            "Epoch 135/200\n",
            " - 0s - loss: 0.0901\n",
            "Epoch 136/200\n",
            " - 0s - loss: 0.0907\n",
            "Epoch 137/200\n",
            " - 0s - loss: 0.0894\n",
            "Epoch 138/200\n",
            " - 0s - loss: 0.0895\n",
            "Epoch 139/200\n",
            " - 0s - loss: 0.0895\n",
            "Epoch 140/200\n",
            " - 0s - loss: 0.0892\n",
            "Epoch 141/200\n",
            " - 0s - loss: 0.0889\n",
            "Epoch 142/200\n",
            " - 0s - loss: 0.0887\n",
            "Epoch 143/200\n",
            " - 0s - loss: 0.0887\n",
            "Epoch 144/200",
            "\n",
            " - 0s - loss: 0.0885\n",
            "Epoch 145/200\n",
            " - 0s - loss: 0.0885\n",
            "Epoch 146/200\n - 0s - loss: 0.0882\n",
            "Epoch 147/200\n",
            " - 0s - loss: 0.0885\n",
            "Epoch 148/200\n",
            " - 0s - loss: 0.0879\n",
            "Epoch 149/200\n",
            " - 0s - loss: 0.0878\n",
            "Epoch 150/200\n",
            " - 0s - loss: 0.0879\n",
            "Epoch 151/200\n",
            " - 0s - loss: 0.0878\n",
            "Epoch 152/200\n",
            " - 0s - loss: 0.0892\n",
            "Epoch 153/200\n - 0s - loss: 0.0878\n",
            "Epoch 154/200\n",
            " - 0s - loss: 0.0893\n",
            "Epoch 155/200\n - 0s - loss: 0.0870\n",
            "Epoch 156/200\n",
            " - 0s - loss: 0.0900\n",
            "Epoch 157/200\n",
            " - 0s - loss: 0.0885\n",
            "Epoch 158/200\n",
            " - 0s - loss: 0.0872\n",
            "Epoch 159/200\n",
            " - 0s - loss: 0.0870\n",
            "Epoch 160/200\n",
            " - 0s - loss: 0.0878\n",
            "Epoch 161/200\n",
            " - 0s - loss: 0.0865\n",
            "Epoch 162/200\n",
            " - 0s - loss: 0.0877\n",
            "Epoch 163/200\n",
            " - 0s - loss: 0.0863\n",
            "Epoch 164/200\n",
            " - 0s - loss: 0.0867\n",
            "Epoch 165/200\n",
            " - 0s - loss: 0.0869\n",
            "Epoch 166/200\n",
            " - 0s - loss: 0.0859\n",
            "Epoch 167/200\n - 0s - loss: 0.0858\n",
            "Epoch 168/200\n",
            " - 0s - loss: 0.0860\n",
            "Epoch 169/200\n",
            " - 0s - loss: 0.0851\n",
            "Epoch 170/200\n",
            " - 0s - loss: 0.0855\n",
            "Epoch 171/200\n",
            " - 0s - loss: 0.0849\n",
            "Epoch 172/200\n",
            " - 0s - loss: 0.0850\n",
            "Epoch 173/200\n",
            " - 0s - loss: 0.0845\n",
            "Epoch 174/200\n",
            " - 0s - loss: 0.0850\n",
            "Epoch 175/200\n",
            " - 0s - loss: 0.0844\n",
            "Epoch 176/200\n",
            " - 0s - loss: 0.0841\n",
            "Epoch 177/200\n",
            " - 0s - loss: 0.0837\n",
            "Epoch 178/200\n",
            " - 0s - loss: 0.0843\n",
            "Epoch 179/200\n",
            " - 0s - loss: 0.0836\n",
            "Epoch 180/200\n",
            " - 0s - loss: 0.0835\n",
            "Epoch 181/200\n",
            " - 0s - loss: 0.0836\n",
            "Epoch 182/200\n",
            " - 0s - loss: 0.0833\n",
            "Epoch 183/200\n",
            " - 0s - loss: 0.0836\n",
            "Epoch 184/200\n",
            " - 0s - loss: 0.0849\n",
            "Epoch 185/200\n",
            " - 0s - loss: 0.0837\n",
            "Epoch 186/200\n",
            " - 0s - loss: 0.0840\n",
            "Epoch 187/200\n",
            " - 0s - loss: 0.0827\n",
            "Epoch 188/200\n",
            " - 0s - loss: 0.0829\n",
            "Epoch 189/200\n",
            " - 0s - loss: 0.0823\n",
            "Epoch 190/200\n",
            " - 0s - loss: 0.0834\n",
            "Epoch 191/200\n",
            " - 0s - loss: 0.0820\n",
            "Epoch 192/200\n",
            " - 0s - loss: 0.0823\n",
            "Epoch 193/200\n",
            " - 0s - loss: 0.0834\n",
            "Epoch 194/200\n",
            " - 0s - loss: 0.0826\n",
            "Epoch 195/200\n",
            " - 0s - loss: 0.0816\n",
            "Epoch 196/200\n",
            " - 0s - loss: 0.0815\n",
            "Epoch 197/200\n",
            " - 0s - loss: 0.0820\n",
            "Epoch 198/200\n",
            " - 0s - loss: 0.0810\n",
            "Epoch 199/200\n",
            " - 0s - loss: 0.0820\n",
            "Epoch 200/200\n",
            " - 0s - loss: 0.0806\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "\u003ckeras.callbacks.callbacks.History at 0x63350b950\u003e"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 25
        }
      ],
      "source": "# fit model\nmodel.fit(X, Y, epochs\u003d200, verbose\u003d2)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[ 0.69547296  0.18415695  0.07763203  0.07747096 -0.00537475]]\n0\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# demonstrate prediction\nx_input, y_star \u003d split_sequence(data.iloc[10:20, :], 5, vocab, labels)\nx_input \u003d x_input[0]\nx_input \u003d x_input.reshape((1, n_steps, n_features))\nyhat \u003d model.predict(x_input, verbose\u003d0)\nprint(yhat)\nprint(y_star[0])\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}